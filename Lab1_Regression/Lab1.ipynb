{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee_4o27S-PhO"
   },
   "source": [
    "# **Introduction**\n",
    "\n",
    "- The used car market is large and dynamic, with prices influenced by multiple factors such as mileage, engine size, fuel efficiency, year of manufacture, and brand. For buyers, accurate price predictions help them avoid overpaying, while for sellers and dealerships, predictive models can guide competitive pricing strategies.\n",
    "\n",
    "- In this lab, students will need to develop predictive models to accurately estimate the used car price based on the car information.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Used car](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTwsNyFobkAjOIx4t1z4eublgdP90ALrglnIA&s)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BOyiK5o-PhP"
   },
   "source": [
    "# **Environment**\n",
    "\n",
    "- We will be using .ipynb (Jupyter Notebook) files. If you don’t already have an environment to run these files, we recommend using **Anaconda**.\n",
    "\n",
    "- The **coding exam** will also use Anaconda, so it’s a good idea to get familiar with it. For guidance, refer to the tutorial anaconda_guide.pptx.\n",
    "\n",
    "- If you are unsure about a function or its parameters, you can use help() to view its documentation. For example: help(train_test_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7zC0h8w-PhP"
   },
   "source": [
    "# **Requirement**\n",
    "\n",
    "- Do it individually! Not as a team! (The team is for final project)\n",
    "\n",
    "- Deadline: **2025/9/25 23:59** (Late submission is not allowed!)\n",
    "\n",
    "- Hand in following files to eeclass in the following format (Do not compressed!)\n",
    "\t- Lab1.ipynb\n",
    "\t- Lab1_basic.csv\n",
    "\t- Lab1_advanced.csv\n",
    "\n",
    "- Lab 1 would be covered on the coding and writing exam next time.\n",
    "\n",
    "- You may modify the provided sample code or add new cells as needed, as long as you meet the requirements.\n",
    "\n",
    "- Responsible TA: Pin-Shun Wang (wangpinshun@gmail.com)\n",
    "\t- Email for questions or visit EECS 639 during TA hours (Make a reservation in advance).\n",
    "\t- No debugging service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33QrHTbA-PhP"
   },
   "source": [
    "# **Penalty Rules**\n",
    "\n",
    "0 points if any of the following conditions happened\n",
    "- Plagiarism\n",
    "- Late submission\n",
    "- Not using the template or importing any other packages\n",
    "- No code(“Lab1.ipynb”) submission on eeclass\n",
    "- No prediction csv files submission on eeclass\n",
    "- Your submission was not generated by your code\n",
    "\n",
    "5 Points would be deducted if your submission format is incorrect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMASY5gD9L0K"
   },
   "source": [
    "# **Lab1: Regression**\n",
    "In this lab, you are required to complete the following tasks:\n",
    "\n",
    "1.  Part I (**60%**) - Preprocess data and implement a linear regression model to predict used car price\n",
    "\n",
    "    - Step 1: Split Data\n",
    "    - Step 2: Preprocess Data\n",
    "    - Step 3: Train Model and Generate Result\n",
    "\n",
    "2.  Part II  (**35%**) - Extend the linear regression model in part I to polynomial regression model and improve prediction performance\n",
    "\n",
    "    - Step 1: Generate the Polynomial Features\n",
    "    - Step 2: Train Model and Generate Result\n",
    "\n",
    "3. Part III (**5%**) – Write a report that answers the given questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egBMMLGV_X_x"
   },
   "source": [
    "### Import Packages\n",
    "\n",
    "⚠️You **cannot** import any other package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "WhhUTua487C-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iuXHvhLALwz"
   },
   "source": [
    "### Global attributes\n",
    "- Define the global attributes. You can also add your own global attributes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wXZVhdp8-flF"
   },
   "outputs": [],
   "source": [
    "training_dataroot = 'train.csv' # Training data file file named as 'train.csv'\n",
    "testing_dataroot = 'test.csv'   # Testing data file named as 'test.csv'\n",
    "basic_output_path = 'Lab1_basic.csv' # Your model prediction in part I to submit to eeclass\n",
    "advanced_output_path = 'Lab1_advanced.csv' # Your model prediction in part II to submit to eeclass\n",
    "\n",
    "basic_output =  [] # save your model prediction in part I\n",
    "advanced_output = [] # save your model prediction in part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyTqIRxQAtWj"
   },
   "source": [
    "### Load the Input File\n",
    "\n",
    "First, load the input file **train.csv** and **test.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "KUzYjoq9AwRp",
    "outputId": "e4faed1e-4af3-433e-fe74-a3bb4be8bd8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B Class</td>\n",
       "      <td>2017</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>26704</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>68.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CL Class</td>\n",
       "      <td>2020</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>55.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V Class</td>\n",
       "      <td>2018</td>\n",
       "      <td>Manual</td>\n",
       "      <td>24164</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>46.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>19498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2017</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>28078</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>65.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C Class</td>\n",
       "      <td>2019</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>15838</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>61.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  year transmission  mileage fuelType  tax   mpg  engineSize  \\\n",
       "0    B Class  2017    Semi-Auto    26704   Diesel  145  68.9         2.1   \n",
       "1   CL Class  2020    Semi-Auto     1000   Diesel  145  55.4         2.0   \n",
       "2    V Class  2018       Manual    24164   Diesel  145  46.3         2.1   \n",
       "3    E Class  2017    Semi-Auto    28078   Diesel  145  65.7         2.0   \n",
       "4    C Class  2019    Semi-Auto    15838   Diesel  145  61.4         2.0   \n",
       "\n",
       "   price  \n",
       "0  13999  \n",
       "1  30389  \n",
       "2  19498  \n",
       "3  21799  \n",
       "4  24498  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Class</td>\n",
       "      <td>2019</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>8478</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>65.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2014</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>60514</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>52.3</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2020</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>2568</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>42.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLC Class</td>\n",
       "      <td>2020</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>2000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C Class</td>\n",
       "      <td>2017</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>20949</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>61.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  year transmission  mileage fuelType  tax   mpg  engineSize\n",
       "0     A Class  2019    Automatic     8478   Diesel  145  65.7         1.5\n",
       "1     E Class  2014    Automatic    60514   Diesel  145  52.3         2.1\n",
       "2     E Class  2020    Automatic     2568   Diesel  145  42.8         2.0\n",
       "3   GLC Class  2020    Semi-Auto     2000   Diesel  145  40.9         2.0\n",
       "4     C Class  2017    Automatic    20949   Diesel  145  61.4         2.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data:  10495\n",
      "Number of testing data:  2624\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(training_dataroot)\n",
    "df_test = pd.read_csv(testing_dataroot)\n",
    "\n",
    "display(df_train.head(5))\n",
    "display(df_test.head(5))\n",
    "print(\"Number of training data: \", len(df_train))\n",
    "print(\"Number of testing data: \", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNpd_FfX_BXI"
   },
   "source": [
    "---\n",
    "# 1. Part I (60%)\n",
    "In part I, you need to implement the linear regression to predict used car price.\n",
    "\n",
    "You will receive full credit (60 points) if the MAPE of your predictions on the testing data is below **20**.\n",
    "\n",
    "⚠️**Please save the prediction result for the testing data in a CSV file and submit it to eeclass. This file will be used to evaluate your assignment**⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bqYH_MvBv4v"
   },
   "source": [
    "## Step 1: Split data\n",
    "\n",
    "Use **train_test_split** from scikit-learn to divide the dataset into a training set and a validation set. The training set is used to fit your regression model, while the validation set is used to evaluate its performance.\n",
    "\n",
    "- **We recommend setting random_state=0 in train_test_split to ensure that the validation data is representative and the evaluation is consistent with the testing data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NVV1mrnM-PhS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2017</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>32000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>30</td>\n",
       "      <td>65.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2014</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>56477</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>30</td>\n",
       "      <td>64.2</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9948</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2016</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>39947</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>56.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>C Class</td>\n",
       "      <td>2016</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>32897</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>125</td>\n",
       "      <td>60.1</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>B Class</td>\n",
       "      <td>2017</td>\n",
       "      <td>Manual</td>\n",
       "      <td>22926</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>20</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  year transmission  mileage fuelType  tax   mpg  engineSize\n",
       "8997   E Class  2017    Automatic    32000   Diesel   30  65.7         2.0\n",
       "5990   E Class  2014    Automatic    56477   Diesel   30  64.2         2.1\n",
       "9948   E Class  2016    Automatic    39947   Diesel  145  56.5         2.1\n",
       "1257   C Class  2016    Automatic    32897   Diesel  125  60.1         2.1\n",
       "3156   B Class  2017       Manual    22926   Diesel   20  68.9         1.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8997    19990\n",
       "5990    11999\n",
       "9948    18498\n",
       "1257    18600\n",
       "3156    13499\n",
       "Name: price, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # TODO Split df_train into training set and validation set\n",
    "\n",
    "x = df_train.drop('price', axis=1)\n",
    "y = df_train['price']\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "#80% training (x_train, y_train)    for trainning\n",
    "#20% validation (x_valid, y_valid) bc we need to check\n",
    "\n",
    "display(x_train.head(5))\n",
    "display(y_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-miSLyewCeME"
   },
   "source": [
    "## Step 2: Preprocess Data\n",
    "\n",
    "As we can see from the input file, the scales of the input features vary significantly. Therefore, it is important to standardize them first to ensure that no single feature dominates the regression results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twrzyvm5-PhS"
   },
   "source": [
    "### Step 2-1: Standardize Continuous Value\n",
    "\n",
    "- As we can see from the input file, the scales of the input features vary significantly. Therefore, it is important to standardize them first to ensure that no single feature dominates the regression results.\n",
    "\n",
    "- Try to use StandardScaler() to transform both the training and validation data.\n",
    "\n",
    "**Note**: Always fit the scaler on the training data only (to compute the mean and standard deviation), and then use the same scaler to transform both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "jR4TYnwwCrci"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before standardization: [2.017e+03 3.200e+04 3.000e+01 6.570e+01 2.000e+00] [2.013e+03 3.100e+04 1.450e+02 5.540e+01 2.200e+00]\n",
      "After standardization: [-0.13912353  0.47465987 -1.51786654  0.68054014 -0.11681279] [-1.95080422  0.42724122  0.2470614   0.00413996  0.23578839]\n",
      "Scaled train example: [-0.13912353  0.47465987 -1.51786654  0.68054014 -0.11681279]\n",
      "Scaled valid example: [-1.95080422  0.42724122  0.2470614   0.00413996  0.23578839]\n"
     ]
    }
   ],
   "source": [
    "cont_columns = ['year', 'mileage', 'tax','mpg', 'engineSize']\n",
    "example_train = x_train[cont_columns]\n",
    "example_valid = x_valid[cont_columns]\n",
    "print(\"Before standardization:\", example_train.iloc[0].values, example_valid.iloc[0].values)\n",
    "\n",
    "# TODO Standardize both example_train and example_valid.\n",
    "scaler = StandardScaler()\n",
    "scale_train = scaler.fit_transform(x_train[cont_columns]) #learns means/std from training and scalling\n",
    "scale_valid = scaler.transform(x_valid[cont_columns])# .transform the same scaling to the valid data\n",
    "\n",
    "print(\"After standardization:\", scale_train[0], scale_valid[0])\n",
    "#Pleng\n",
    "print(\"Scaled train example:\", scale_train[0])\n",
    "print(\"Scaled valid example:\", scale_valid[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwqNbxP5-PhS"
   },
   "source": [
    "### Step 2-2: Encode Categorical Value\n",
    "\n",
    "- The dataset contains several categorical columns. For example, the model column has 26 distinct car models. Since regression models cannot directly handle categorical values, we need to encode these features first.\n",
    "\n",
    "- We can use one hot encoding to tackle such issue. It can creates a new binary feature for each distinct category. The column corresponding to the observed category is set to 1, while all others are 0.\n",
    "\n",
    "**Note**: Just like with scaling, you should fit the encoder on the training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ZIg-_uRN-PhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encoding:\n",
      "Feature: ['model' 'transmission' 'fuelType']\n",
      "====================================================================================================\n",
      "After encoding:\n",
      "Feature: ['model_ A Class' 'model_ B Class' 'model_ C Class' 'model_ CL Class'\n",
      " 'model_ CLA Class' 'model_ CLC Class' 'model_ CLK' 'model_ CLS Class'\n",
      " 'model_ E Class' 'model_ G Class' 'model_ GL Class' 'model_ GLA Class'\n",
      " 'model_ GLB Class' 'model_ GLC Class' 'model_ GLE Class'\n",
      " 'model_ GLS Class' 'model_ M Class' 'model_ R Class' 'model_ S Class'\n",
      " 'model_ SL CLASS' 'model_ SLK' 'model_ V Class' 'model_ X-CLASS'\n",
      " 'model_180' 'model_200' 'model_220' 'model_230' 'transmission_Automatic'\n",
      " 'transmission_Manual' 'transmission_Other' 'transmission_Semi-Auto'\n",
      " 'fuelType_Diesel' 'fuelType_Hybrid' 'fuelType_Other' 'fuelType_Petrol']\n"
     ]
    }
   ],
   "source": [
    "#FOR SCALING AND ENCODING FOR MACHINE TO UNDERSTAND OUR STUFFS\n",
    "category_columns = ['model','transmission', 'fuelType']\n",
    "example_train = x_train[category_columns]\n",
    "example_valid = x_valid[category_columns]\n",
    "\n",
    "# set handle_unknown='ignore' to prevent unseen categories in validation data\n",
    "onehotencoder = OneHotEncoder(handle_unknown='ignore')# initiliazed \n",
    "\n",
    "# TODO Encode example_train and example_valid\n",
    "onehot_train = onehotencoder.fit_transform(example_train)# fit on training set and transform\n",
    "onehot_valid = onehotencoder.transform(example_valid)# transform the valid set using the same encoding\n",
    "\n",
    "print(\"Before encoding:\")\n",
    "print(f\"Feature: {example_train.columns.values}\")\n",
    "print('=' * 100)\n",
    "print(\"After encoding:\")\n",
    "print(f\"Feature: {onehotencoder.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGCk9pr1-PhS"
   },
   "source": [
    "### Step 2-3: Use ColumnTransformer\n",
    "\n",
    "- The input CSV file contains both continuous and categorical features. Since these types of data require different preprocessing steps, it is convenient to use ColumnTransformer in scikit-learn to apply the appropriate transformations to each column.\n",
    "\n",
    "- Using the preprocessing steps we defined earlier (scaling for continuous features and one-hot encoding for categorical features), define a preprocessor that transforms the input data into a format suitable for linear regression, all in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "OFkak7q9-PhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8396, 40)\n",
      "(2099, 40)\n"
     ]
    }
   ],
   "source": [
    "# TODO Define the preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"numerical\", StandardScaler() , cont_columns),\n",
    "    (\"category\", OneHotEncoder(handle_unknown = 'ignore') , category_columns)\n",
    "])\n",
    "\n",
    "# TODO Preprocess continuous data and categorical data at the same time\n",
    "preprocess_train = preprocessor.fit_transform(x_train) # transform x_train\n",
    "preprocess_valid = preprocessor.transform(x_valid) # transform x_valid\n",
    "\n",
    "print(preprocess_train.shape)\n",
    "print(preprocess_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q4qKXbDDmG9"
   },
   "source": [
    "## Step 3: Train Model and Generate Result\n",
    "\n",
    "- Now that you know how to preprocess the data, let’s train a linear regression model. For convenience, you don’t need to preprocess the data separately before training. Instead, you can use a **Pipeline** to combine the preprocessor and the regression model, so that you can perform preprocessing and model training in a single step.\n",
    "\n",
    "- In this lab, we use Mean Absolute Percentage Error (MAPE) to evaluate the performance. It measures the average absolute difference between the predicted and actual values, expressed as a percentage of the actual values. It is more interpretable because it provides a relative error in percentage terms, making it easier to understand and compare across different datasets or scales. You can calculate it with the imported function **mean_absolute_percentage_error**. The formula is as below:\n",
    "<div align=\"center\">\n",
    "\n",
    "![MAPE_formula](https://ithelp.ithome.com.tw/upload/images/20210929/20142004n36Qnhw9js.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "- Save the predicted values for the testing dataset in `basic_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "coo82WvZDpMq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE (%): 18.506788782241856\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# TODO Fit the model\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# TODO Evaluate your model using validation data(MAPE)\n",
    "y_pred = pipeline.predict(x_valid)\n",
    "mape = mean_absolute_percentage_error(y_valid, y_pred)\n",
    "print(\"MAPE (%):\", mape * 100)\n",
    "\n",
    "# TODO Predict used car price in the testing data\n",
    "basic_output = pipeline.predict(df_test).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW3NrFmGEEiG"
   },
   "source": [
    "### Write the Output File\n",
    "\n",
    "Write the prediction in *basic_output* to Lab1_basic.csv\n",
    "> Format: 'ID', 'price'\n",
    "\n",
    "⚠️**Remember to submit it to eeclass. This file will be used to evaluate your part I**⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Mo7rdhx0EFLn"
   },
   "outputs": [],
   "source": [
    "# Assume that basic_output is a list with length = 2624\n",
    "with open(basic_output_path, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerow(['ID', 'price'])\n",
    "  for i in range(len(basic_output)):\n",
    "    writer.writerow([i,basic_output[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1O2l8d2E3he"
   },
   "source": [
    "# 2. Part II (35%)\n",
    "In part II, you need to implement the polynomial regression to improve your price predictions. Polynomial regression is useful because it can capture the non-linear relationships between the input features and the target variable.\n",
    "\n",
    "You will receive full credit (35 points) if the MAPE of your predictions on the testing data is below **15**.\n",
    "\n",
    "⚠️**Please save the prediction result for the testing data in a CSV file and submit it to eeclass. This file will be used to evaluate your assignment**⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYTyQ4Qt-PhT"
   },
   "source": [
    "---\n",
    "## Step 1: Generate the Polynomial Features\n",
    "\n",
    "To implement polynomial regression, we first need to expand the original input features into polynomial features.For example, suppose we have two input features (${x1}$, ${x2}$), and we want to generate polynomial features up to degree 3. The transformed features would include:\n",
    "- Degree 1:  (${x1}$, ${x2}$)\n",
    "- Degree 2: (${x1^2}$, ${x2^2}$, ${x1x2}$)\n",
    "- Degree 3: (${x1^3}$, ${x2^3}$, ${x1^2x2}$, ${x1x2^2}$)\n",
    "\n",
    "In total, this gives us 9 polynomial features. By applying our regression model in basic part to these expanded features, we can capture non-linear relationships between the input variables and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UKqbxIXb-PhT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Feature shape:  (8396, 2)\n",
      "Polynomial Feature shape:  (8396, 9)\n"
     ]
    }
   ],
   "source": [
    "example_columns = ['tax', 'mpg']\n",
    "example_train = x_train[example_columns]\n",
    "example_valid = x_valid[example_columns]\n",
    "\n",
    "# set include_bias=False since the regression model would consider intercept term itself\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "# TODO Generate the polynomial features for example_train and example_valid\n",
    "poly_train = poly.fit_transform(example_train)\n",
    "poly_valid = poly.transform(example_valid)\n",
    "\n",
    "print(\"Original Feature shape: \", example_train.shape)\n",
    "print(\"Polynomial Feature shape: \", poly_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLYo34fC-PhT"
   },
   "source": [
    "## Step 2: Train Model and Generate Result\n",
    "\n",
    "Extend the **ColumnTransformer** you defined in the basic part by adding **PolynomialFeatures**, and use it to generate predictions on the testing dataset. To apply polynomial expansion and standardization together, wrap them in a Pipeline so they are processed in the correct order.\n",
    "\n",
    "**Hint**: You can experiment with different polynomial degrees, or try alternative linear models such as **Ridge** or **Lasso** regression to improve performance.\n",
    "\n",
    "- Save the predicted values for the testing dataset in `advanced_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ruw5auxI-PhT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE (%): 12.74293403558509\n"
     ]
    }
   ],
   "source": [
    "# TODO Define a new preprocessor that includes PolynomialFeatures\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),  # try degree=3 later if needed\n",
    "        (\"scaler\", StandardScaler()),]), cont_columns),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), category_columns),\n",
    "])\n",
    "\n",
    "# TODO Build your own pipeline with different regression model\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", Ridge(alpha=1.0))  # we can try 0.1, 0.3, 1.0, 3.0, 10.0\n",
    "])\n",
    "\n",
    "# TODO Fit the model\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# TODO Evaluate your model using validation data\n",
    "y_pred = pipeline.predict(x_valid)\n",
    "mape = mean_absolute_percentage_error(y_valid, y_pred)\n",
    "print(\"MAPE (%):\", mape * 100)\n",
    "\n",
    "# TODO Predict used car price in the testing data\n",
    "advanced_output = pipeline.predict(df_test).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRmHTp67-PhT"
   },
   "source": [
    "### Write the Output File\n",
    "\n",
    "Write the prediction in *advanced_output* to Lab1_advanced.csv\n",
    "> Format: 'ID', 'price'\n",
    "\n",
    "⚠️**Remember to submit it to eeclass. This file will be used to evaluate your part II**⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "c3alLSgU-PhT"
   },
   "outputs": [],
   "source": [
    "# Assume that advanced_output is a list with length = 2624\n",
    "with open(advanced_output_path, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerow(['ID', 'price'])\n",
    "  for i in range(len(advanced_output)):\n",
    "    writer.writerow([i,advanced_output[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_d-vJGU-PhT"
   },
   "source": [
    "# Part III (5%)\n",
    "\n",
    "Answer each question in the below markdown cell.\n",
    "\n",
    "1. Write down your regression equation in basic part. For example: 1 + 20*x1 + 30*x2 (1%)\n",
    "\n",
    "2. When standardizing input features, why do we standardize each feature across all samples, rather than standardizing each sample individually? (1%)\n",
    "\n",
    "3. Why don’t we simply map each categorical value to an integer (0 to number of classes – 1)? What advantages does one-hot encoding provide compared to this approach? (1%)\n",
    "\n",
    "4. In the advanced part, should we generate polynomial features first or standardize the data first? Explain your reasoning. (2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUCU_BiA-PhU"
   },
   "source": [
    "## Your answer to the questions\n",
    "1.The regression equation in the basic part is represeted as y= β_0 + β_1x_1 + β_2x_2 + ⋯ + β_nx_n\n",
    "\n",
    "Think of it like a simple recipe. The model predicts the car price (y) by starting with a base price (β_0), then adding up the contributions of each ingredient (the features, or x_1, x_2, ...). Each feature's contribution is multiplied by a special number (β_1, β_2, ...) that the model learned from the data.\n",
    "\n",
    "2.Imagine you have two features: mileage (which can be a huge number) and engine size (which is a small number). If you don't standardize, the model might think mileage is way more important just because its numbers are bigger. By standardizing, you put both features on a level playing field, ensuring the model treats them fairly.\n",
    "\n",
    "\n",
    "3.This is like giving your model a misleading hint. It might think that \"blue\" is \"better\" or \"more than\" \"red\" just because 2 is bigger than 1. One-hot encoding avoids this by creating a separate column for each color. So, for a red car, the \"Red\" column is 1 and all other color columns are 0. This way, the model knows each color is its own unique thing without any false ranking.\n",
    "\n",
    "\n",
    "4.Always make the polynomial features first! The polynomial transformation uses the raw values of your original features to create new, more complex ones. If you standardized first, you'd mess up those original values and the new features wouldn't make sense. So, you create the new features first, and then you standardize everything to get it ready for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVz38ASe-gGV"
   },
   "source": [
    "# Save the Code File\n",
    "Please save your code as a Jupyter Notebook file (Lab1.ipynb) and submit it to eeclass along with your prediction files (Lab1_basic.csv and Lab1_advanced.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
